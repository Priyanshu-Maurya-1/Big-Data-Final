{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e12c1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "from config import client, db, collection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af0aaf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Rows (Records): 735502\n",
      "Number of Columns (Attributes): 18\n"
     ]
    }
   ],
   "source": [
    "\n",
    "row_count = collection.count_documents({})  \n",
    "print(f\"Number of Rows (Records): {row_count}\")\n",
    "\n",
    "sample_record = collection.find_one()  \n",
    "column_count = len(sample_record.keys())  \n",
    "print(f\"Number of Columns (Attributes): {column_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574cb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dff49a7",
   "metadata": {},
   "source": [
    "# Clean the data (Silver Layer) (using DB Queries or Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "555c8f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "_id                        0\n",
      "Bike ID                    0\n",
      "Birth Year                 0\n",
      "End Station ID             0\n",
      "End Station Latitude       0\n",
      "End Station Longitude      0\n",
      "End Station Name           0\n",
      "Gender                     0\n",
      "Start Station ID           0\n",
      "Start Station Latitude     0\n",
      "Start Station Longitude    0\n",
      "Start Station Name         0\n",
      "Start Time                 0\n",
      "Stop Time                  0\n",
      "Trip Duration              0\n",
      "Trip_Duration_in_min       0\n",
      "Unnamed: 0                 0\n",
      "User Type                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#i am defining a function to counnt all the missinng values\n",
    "import pandas as pd\n",
    "def count_missing_values(data):\n",
    "    missing_counts = data.isnull().sum()\n",
    "    print(\"Missing values in each column:\")\n",
    "    print(missing_counts)\n",
    "    return missing_counts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    raw_data = pd.DataFrame(list(collection.find()))\n",
    "    missing_counts = count_missing_values(raw_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e169140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddabcef3",
   "metadata": {},
   "source": [
    "## Work to do\n",
    "1.Drop the id column\n",
    "\n",
    "2.Fill the missing values eg.with mean and dropping the duplicate values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b712117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 735502 records from MongoDB.\n",
      "Cleaned data has 339620 records.\n",
      "Cleaned data saved to MongoDB (Silver Layer). Records: 339620\n"
     ]
    }
   ],
   "source": [
    "def load_data_from_mongodb():\n",
    "    data = pd.DataFrame(list(collection.find()))\n",
    "    return data\n",
    "\n",
    "def clean_data(data):\n",
    "    if '_id' in data.columns:\n",
    "        data.drop(columns=['_id'], inplace=True)\n",
    "\n",
    "    data.fillna({\n",
    "        'Start Station Name': 'Unknown',\n",
    "        'End Station Name': 'Unknown',\n",
    "        'User Type': 'Unknown',\n",
    "        'Birth Year': 0,\n",
    "        'Gender': 0,\n",
    "    }, inplace=True)\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data['Trip Duration'] = data['Trip Duration'].astype(int)\n",
    "    data['Trip_Duration_in_min'] = data['Trip_Duration_in_min'].astype(int)\n",
    "    data['Birth Year'] = data['Birth Year'].astype(int)\n",
    "    data['Gender'] = data['Gender'].astype(int)\n",
    "\n",
    "    data = data[data['Trip Duration'] > 0]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def save_cleaned_data_to_mongodb(cleaned_data):\n",
    "    silver_collection = db['Trips_Silver']\n",
    "    silver_collection.delete_many({})  # to Clear existing data\n",
    "    silver_collection.insert_many(cleaned_data.to_dict('records'))\n",
    "    print(f\"Cleaned data saved to MongoDB (Silver Layer). Records: {len(cleaned_data)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    raw_data = load_data_from_mongodb()\n",
    "    print(f\"Loaded {len(raw_data)} records from MongoDB.\")\n",
    "\n",
    "    cleaned_data = clean_data(raw_data)\n",
    "    print(f\"Cleaned data has {len(cleaned_data)} records.\")\n",
    "    \n",
    "    save_cleaned_data_to_mongodb(cleaned_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fee6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05ea5cff",
   "metadata": {},
   "source": [
    "### I have saved the cleaned silver data in a new mongodb collection, i can just update the existing one still for sake of debugging and understanding and no space constraints i have done it in two different collections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4805952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e22efddf",
   "metadata": {},
   "source": [
    "# Create Aggregated dataset(s) (Gold Layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd86966c",
   "metadata": {},
   "source": [
    "### for gold layer im doing this aggregations\n",
    "\n",
    "Total trips per user type.\n",
    "\n",
    "Average trip duration by station.\n",
    "\n",
    "Popular start and end stations.\n",
    "\n",
    "Total trips per day.\n",
    "\n",
    "Trips by Gender and Average trip Duration\n",
    "\n",
    "Busiest Days\n",
    "\n",
    "Bike usage by count\n",
    "\n",
    "longest Trips \n",
    "\n",
    "Busiest Hours\n",
    "\n",
    "Trips by day of week\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8e66ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 339620 records from Silver Layer.\n",
      "Aggregated datasets saved to MongoDB (Gold Layer).\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "from datetime import datetime, date \n",
    "\n",
    "silver_collection = db['Trips_Silver']\n",
    "gold_collection = db['Trips_Gold']\n",
    "\n",
    "def load_cleaned_data():\n",
    "    data = pd.DataFrame(list(silver_collection.find()))\n",
    "    return data\n",
    "\n",
    "def create_aggregations(data):\n",
    "    aggregations = {}\n",
    "\n",
    "    # 1. Total trips per user type\n",
    "    trips_per_user_type = data.groupby('User Type').size().reset_index(name='Total Trips')\n",
    "    aggregations['Trips_Per_User_Type'] = trips_per_user_type\n",
    "\n",
    "    # 2. Average trip duration by start station\n",
    "    avg_duration_by_station = data.groupby('Start Station Name')['Trip_Duration_in_min'].mean().reset_index(name='Avg Duration (min)')\n",
    "    aggregations['Avg_Duration_By_Station'] = avg_duration_by_station\n",
    "\n",
    "    # 3. Popular start and end stations\n",
    "    popular_start_stations = data['Start Station Name'].value_counts().reset_index(name='Trip Count').rename(columns={'index': 'Station Name'})\n",
    "    aggregations['Popular_Start_Stations'] = popular_start_stations\n",
    "\n",
    "    popular_end_stations = data['End Station Name'].value_counts().reset_index(name='Trip Count').rename(columns={'index': 'Station Name'})\n",
    "    aggregations['Popular_End_Stations'] = popular_end_stations\n",
    "\n",
    "    # 4. Total trips per day\n",
    "    data['Start Time'] = pd.to_datetime(data['Start Time'])  # Ensure Start Time is datetime\n",
    "    trips_per_day = data.groupby(data['Start Time'].dt.date).size().reset_index(name='Total Trips').rename(columns={'Start Time': 'Date'})\n",
    "    aggregations['Trips_Per_Day'] = trips_per_day\n",
    "    \n",
    "    busiest_days = data.groupby(data['Start Time'].dt.date).size() \\\n",
    "                   .reset_index(name='Total Trips') \\\n",
    "                   .sort_values(by='Total Trips', ascending=False) \\\n",
    "                   .head(10)\n",
    "    aggregations['Busiest_Days'] = busiest_days\n",
    "\n",
    "    trips_by_gender = data.groupby('Gender').size().reset_index(name='Total Trips')\n",
    "    aggregations['Trips_By_Gender'] = trips_by_gender\n",
    "\n",
    "    avg_duration_by_gender = data.groupby('Gender')['Trip_Duration_in_min'].mean() \\\n",
    "                             .reset_index(name='Avg Duration (min)')\n",
    "    aggregations['Avg_Trip_Duration_By_Gender'] = avg_duration_by_gender\n",
    "\n",
    "    most_used_bikes = data['Bike ID'].value_counts().reset_index(name='Trip Count') \\\n",
    "                     .rename(columns={'index': 'Bike ID'}).head(10)\n",
    "    aggregations['Most_Used_Bikes'] = most_used_bikes\n",
    "\n",
    "    longest_trips = data.sort_values(by='Trip Duration', ascending=False) \\\n",
    "                    .head(10)[['Trip Duration', 'Start Station Name', 'End Station Name']]\n",
    "    aggregations['Longest_Trips'] = longest_trips\n",
    "\n",
    "    \n",
    "    longest_trips = data.sort_values(by='Trip Duration', ascending=False) \\\n",
    "                    .head(10)[['Trip Duration', 'Start Station Name', 'End Station Name']]\n",
    "    aggregations['Longest_Trips'] = longest_trips\n",
    "\n",
    "    popular_routes = data.groupby(['Start Station Name', 'End Station Name']).size() \\\n",
    "                     .reset_index(name='Trip Count') \\\n",
    "                     .sort_values(by='Trip Count', ascending=False) \\\n",
    "                     .head(10)\n",
    "    aggregations['Popular_Routes'] = popular_routes\n",
    "\n",
    "    popular_routes = data.groupby(['Start Station Name', 'End Station Name']).size() \\\n",
    "                     .reset_index(name='Trip Count') \\\n",
    "                     .sort_values(by='Trip Count', ascending=False) \\\n",
    "                     .head(10)\n",
    "    aggregations['Popular_Routes'] = popular_routes\n",
    "\n",
    "    \n",
    "    data['Day of Week'] = pd.to_datetime(data['Start Time']).dt.day_name()\n",
    "    trips_by_day = data.groupby('Day of Week').size().reset_index(name='Total Trips') \\\n",
    "                   .sort_values(by='Total Trips', ascending=False)\n",
    "    aggregations['Trips_By_Day_Of_Week'] = trips_by_day\n",
    "\n",
    "\n",
    "    return aggregations\n",
    "\n",
    "def save_aggregations_to_mongodb(aggregations):\n",
    "    gold_collection.delete_many({})  # Clear existing data\n",
    "    \n",
    "    for key, df in aggregations.items():\n",
    "        # Convert datetime.date to datetime.datetime\n",
    "        data = df.to_dict('records')\n",
    "        for record in data:\n",
    "            for field, value in record.items():\n",
    "                if isinstance(value, date):\n",
    "                    record[field] = datetime.combine(value, datetime.min.time()) \n",
    "        \n",
    "        gold_collection.insert_one({\n",
    "            'aggregation_name': key,\n",
    "            'data': data\n",
    "        })\n",
    "    \n",
    "    print(f\"Aggregated datasets saved to MongoDB (Gold Layer).\")\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    cleaned_data = load_cleaned_data()\n",
    "    print(f\"Loaded {len(cleaned_data)} records from Silver Layer.\")\n",
    "\n",
    "    aggregated_data = create_aggregations(cleaned_data)\n",
    "\n",
    "    save_aggregations_to_mongodb(aggregated_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408cb7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
